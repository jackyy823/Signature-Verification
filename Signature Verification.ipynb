{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15dc23f3",
   "metadata": {},
   "source": [
    "# Signature Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f544534",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from PIL import Image\n",
    "import PIL.ImageOps    \n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.utils\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a8b274",
   "metadata": {},
   "source": [
    "## Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b227d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing images\n",
    "def imshow(img, text=None):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic', fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()    \n",
    "\n",
    "# plotting data\n",
    "def show_plot(iteration, loss):\n",
    "    plt.plot(iteration, loss)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9fd1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetworkDataset(Dataset):\n",
    "    def __init__(self, imageFolderDataset, transform=None, should_invert=True):\n",
    "        self.imageFolderDataset = imageFolderDataset    \n",
    "        self.transform = transform\n",
    "        self.should_invert = should_invert\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # TODO: need to update how images are chosen\n",
    "        img0_tuple = random.choice(self.imageFolderDataset.imgs)\n",
    "        # need to make sure approx 50% of images are in the same class\n",
    "        should_get_same_class = random.randint(0,1) \n",
    "        if should_get_same_class:\n",
    "            while True:\n",
    "                # keep looping till the same class image is found\n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n",
    "                if img0_tuple[1] == img1_tuple[1]:\n",
    "                    break\n",
    "        else:\n",
    "            while True:\n",
    "                # keep looping till a different class image is found\n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n",
    "                if img0_tuple[1] != img1_tuple[1]:\n",
    "                    break\n",
    "\n",
    "        img0 = Image.open(img0_tuple[0])\n",
    "        img1 = Image.open(img1_tuple[0])\n",
    "        img0 = img0.convert(\"L\")\n",
    "        img1 = img1.convert(\"L\")\n",
    "        \n",
    "        if self.should_invert:\n",
    "            img0 = PIL.ImageOps.invert(img0)\n",
    "            img1 = PIL.ImageOps.invert(img1)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "        \n",
    "        return img0, img1 , torch.from_numpy(np.array([int(img1_tuple[1]!=img0_tuple[1])],dtype=np.float32))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imageFolderDataset.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf8e4d2",
   "metadata": {},
   "source": [
    "## Siamese Code Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9caa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \n",
    "        self.cnn1 = nn.Sequential( \n",
    "        nn.Conv2d(1, 96, kernel_size=11, stride=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2),\n",
    "        nn.MaxPool2d(3, stride=2),\n",
    "\n",
    "        nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2),\n",
    "        nn.MaxPool2d(3, stride=2),\n",
    "        nn.Dropout2d(p=0.3),\n",
    "\n",
    "        nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(3, stride=2),\n",
    "        nn.Dropout2d(p=0.3))\n",
    "\n",
    "        # defining the fully connected layers\n",
    "        self.fc1 = nn.Sequential(\n",
    "        # first dense layer\n",
    "        nn.Linear(25600, 1024),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout2d(p=0.5),\n",
    "        # second dense layer\n",
    "        nn.Linear(1024, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        # final dense layer\n",
    "        nn.Linear(128, 2))\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        # forward pass \n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # forward pass of input 1\n",
    "        output1 = self.forward_once(input1)\n",
    "        # forward pass of input 2\n",
    "        output2 = self.forward_once(input2)\n",
    "        # returning the feature vectors of two inputs\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a75679",
   "metadata": {},
   "source": [
    "## Contrastive Loss Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a93c0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        # find the pairwise distance or eucledian distance of two output feature vectors\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        # perform contrastive loss calculation with the distance\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "        (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc7b803",
   "metadata": {},
   "source": [
    "## Oneshot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5201b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Oneshot(model, img1, img2):\n",
    "    # gives you the feature vector of both inputs\n",
    "    output1, output2 = model(img1.cuda(),img2.cuda())\n",
    "    # compute the distance \n",
    "    euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "    # with certain threshold of distance say its similar or not\n",
    "    if eucledian_distance > 0.5:\n",
    "        print(\"Original Signature\")\n",
    "    else:\n",
    "        print(\"Forged Signature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68548daa",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372d73ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dataset = datasets.ImageFolder(root=\"./sign_data/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21685c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset,\n",
    "                                        transform=transforms.Compose([transforms.Resize((100,100)),\n",
    "                                                                      transforms.ToTensor()\n",
    "                                                                      ]),\n",
    "                                        should_invert=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e63a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_dataloader = DataLoader(siamese_dataset,\n",
    "                        shuffle=True,\n",
    "                        #num_workers=8,\n",
    "                        batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0161f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(vis_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bc094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch = next(dataiter)\n",
    "concatenated = torch.cat((example_batch[0],example_batch[1]),0)\n",
    "imshow(torchvision.utils.make_grid(concatenated))\n",
    "print(example_batch[2].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5da54ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "loss_history = [] \n",
    "iteration_number = 0\n",
    "train_batch_size = 64\n",
    "train_number_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031bd3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(siamese_dataset,\n",
    "                        shuffle=True,\n",
    "                        #num_workers=8,\n",
    "                        batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b1cd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = SiameseNetwork().cuda()\n",
    "net = SiameseNetwork().to('cpu')\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71934d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0, train_number_epochs):\n",
    "    for i, data in enumerate(train_dataloader,0):\n",
    "        img0, img1, label = data\n",
    "        # img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()\n",
    "        img0, img1, label = img0.to('cpu'), img1.to('cpu'), label.to('cpu')\n",
    "        optimizer.zero_grad()\n",
    "        output1,output2 = net(img0,img1)\n",
    "        loss_contrastive = criterion(output1,output2,label)\n",
    "        loss_contrastive.backward()\n",
    "        optimizer.step()\n",
    "        if i % 10 == 0 :\n",
    "            print(\"Epoch number {}\\n Current loss {}\\n\".format(epoch,loss_contrastive.item()))\n",
    "            iteration_number += 10\n",
    "            counter.append(iteration_number)\n",
    "            loss_history.append(loss_contrastive.item())\n",
    "show_plot(counter,loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927578b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
