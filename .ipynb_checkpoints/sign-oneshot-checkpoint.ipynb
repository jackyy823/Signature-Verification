{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Input data files are available in the read-only \"../input/\" directory\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_dir=\"/kaggle/input/signature-verification-dataset/sign_data/train\"\n",
    "train_csv=\"/kaggle/input/signature-verification-dataset/sign_data/train_data.csv\"\n",
    "test_csv=\"/kaggle/input/signature-verification-dataset/sign_data/test_data.csv\"\n",
    "test_dir=\"/kaggle/input/signature-verification-dataset/sign_data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(train_csv)\n",
    "df_train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_train(train_csvfile):\n",
    "    x1=[]\n",
    "    x2=[]\n",
    "    y_train=[]\n",
    "    for i in range(0,2000):\n",
    "        image1_path=os.path.join(train_dir,train_csvfile.iat[i,0])\n",
    "        image2_path=os.path.join(train_dir,train_csvfile.iat[i,1])\n",
    "        img1=cv2.imread(image1_path)\n",
    "        img1= cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "        img1=cv2.resize(img1,(150,150))\n",
    "        x1.append(img1)\n",
    "        img2=cv2.imread(image2_path)\n",
    "        img2= cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "        img2=cv2.resize(img2,(150,150))\n",
    "        x2.append(img2)\n",
    "        y_train.append(train_csvfile.iat[i,2])\n",
    "#         print(i)\n",
    "#         l.append([img1,img2,train_csvfile.iat[i,2]])\n",
    "    x1=np.array(x1).astype(np.float32)/255.0\n",
    "    x2=np.array(x2).astype(np.float32)/255.0\n",
    "    y_train=np.array(y_train).astype(np.float32)\n",
    "    \n",
    "    return x1,x2,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_test(test_csvfile):\n",
    "    x1=[]\n",
    "    x2=[]\n",
    "    y_train=[]\n",
    "    for i in range(2000,4000):\n",
    "        image1_path=os.path.join(test_dir,test_csvfile.iat[i,0])\n",
    "        image2_path=os.path.join(test_dir,test_csvfile.iat[i,1])\n",
    "        img1=cv2.imread(image1_path)\n",
    "        img1= cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "        img1=cv2.resize(img1,(150,150))\n",
    "        x1.append(img1)\n",
    "        img2=cv2.imread(image2_path)\n",
    "        img2= cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "        img2=cv2.resize(img2,(150,150))\n",
    "        x2.append(img2)\n",
    "        y_train.append(test_csvfile.iat[i,2])\n",
    "#         print(i)\n",
    "#         l.append([img1,img2,train_csvfile.iat[i,2]])\n",
    "    x1=np.array(x1).astype(np.float32)/255.0\n",
    "    x2=np.array(x2).astype(np.float32)/255.0\n",
    "    y_train=np.array(y_train).astype(np.float32)\n",
    "    \n",
    "    return x1,x2,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv(test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt1,xt2,yt=dataset_test(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs1,xs2,ys=dataset_train(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dist1(xy):\n",
    "    x, y = xy\n",
    "    sum_abs = K.sum(K.abs(x - y), axis=1, keepdims=True)\n",
    "#     return sum_abs\n",
    "    return K.maximum(sum_abs, K.epsilon())\n",
    "def dist2(xy):\n",
    "    x,y=xy\n",
    "    sum_square=K.sum(K.square(x-y),axis=1,keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def dist3(xy):\n",
    "    x,y=xy\n",
    "    return K.sqrt(K.mean(K.square(x-y),axis=1,keepdims=True))\n",
    "def dist4(xy):\n",
    "    x,y=xy\n",
    "    ss=K.sum(K.square(x-y),axis=1,keepdims=True)\n",
    "    return K.sqrt(ss)/x.shape[1]\n",
    "\n",
    "\n",
    "input1=keras.layers.Input(shape=(150,150,1))\n",
    "# x=keras.layers.Flatten()(input1)\n",
    "x=keras.layers.Conv2D(64,(10,10),activation='relu')(input1)\n",
    "x=keras.layers.MaxPooling2D(2,2)(x)\n",
    "# x=BatchNormalization()(x)\n",
    "x=keras.layers.Dropout(0.5)(x)\n",
    "# x=keras.layers.Conv2D(128,(7,7),activation='relu')(x)\n",
    "# x=keras.layers.MaxPooling2D(2,2)(x)\n",
    "x=keras.layers.Conv2D(100,(7,7),activation='relu')(x)\n",
    "# x=BatchNormalization()(x)\n",
    "x=keras.layers.MaxPooling2D(2,2)(x)\n",
    "x=keras.layers.Dropout(0.5)(x)\n",
    "# x=keras.layers.Conv2D(258,(4,4),activation='relu')(x)\n",
    "# x=keras.layers.MaxPooling2D(2,2)(x)\n",
    "x=keras.layers.Flatten()(x)\n",
    "# x=keras.layers.Dense(4096,activation='relu')(x)\n",
    "x=keras.layers.Dense(500,activation='relu')(x)\n",
    "# x=BatchNormalization()(x)\n",
    "dense=keras.models.Model(inputs=input1,outputs=x)\n",
    "\n",
    "\n",
    "img1=keras.layers.Input(shape=(150,150,1))\n",
    "img2=keras.layers.Input(shape=(150,150,1))\n",
    "dense1=dense(img1)\n",
    "dense2=dense(img2)\n",
    "fc=keras.layers.Lambda(dist3)([dense1,dense2])\n",
    "# fc=keras.layers.Dense(100,activation='relu')(fc)\n",
    "fc=keras.layers.Dense(1,activation='sigmoid')(fc)\n",
    "\n",
    "m=keras.models.Model(inputs=[img1,img2],outputs=fc)\n",
    "\n",
    "m.compile(loss = \"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "m.summary()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit([xs1,xs2],ys,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.evaluate([xt1,xt2],yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(stored,image):\n",
    "    img2=np.array([image])\n",
    "    for i in range(0,stored.shape[0]):\n",
    "        img1=np.array([stored[i]])\n",
    "        pred=m.predict([img1,img2])\n",
    "        print(pred)\n",
    "        if(pred<0.5):\n",
    "            print(\"matched\",i)\n",
    "            return\n",
    "    print(\"unmatched\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_signatures=xt1[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(database_signatures,xt1[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(xs1[223])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(xt1[223])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
